# Titanic Survival Prediction

Projet d'ingÃ©nierie logicielle - PrÃ©diction de survie sur le Titanic avec Machine Learning

[![Python CI](https://github.com/Makamtrr/Dvt_Logiciel/actions/workflows/python-ci.yml/badge.svg)](https://github.com/Makamtrr/Dvt_Logiciel/actions)

## ğŸ“‹ Description

Ce projet implÃ©mente un modÃ¨le de Machine Learning pour prÃ©dire la survie des passagers du Titanic. Il a Ã©tÃ© dÃ©veloppÃ© dans le cadre du BUT VCOD 2025-2026 Ã  l'IUT Paris CitÃ©, en appliquant les bonnes pratiques d'ingÃ©nierie logicielle.

**Technologies utilisÃ©es:**
- Python 3.9+
- scikit-learn (Random Forest)
- pandas, numpy
- pytest (tests unitaires, 100% de couverture)
- Docker & Docker Compose
- GitHub Actions (CI/CD)

**DonnÃ©es:** [Kaggle Titanic Competition](https://www.kaggle.com/c/titanic)

## ğŸš€ Installation

### PrÃ©requis
- Python 3.9 ou supÃ©rieur
- pip
- (Optionnel) Docker et Docker Compose

### Installation locale

```bash
# Cloner le repository
git clone https://github.com/Makamtrr/Dvt_Logiciel.git
cd Dvt_Logiciel

# CrÃ©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# Installer le projet en mode dÃ©veloppement
pip install -e .
```

## ğŸ¯ Utilisation

### ExÃ©cution locale

```bash
# ExÃ©cuter le pipeline complet
python src/main.py
```

Le fichier de prÃ©dictions sera gÃ©nÃ©rÃ© dans `output/submission.csv`.

### ExÃ©cution avec Docker

```bash
# Construire et lancer le conteneur
docker-compose up --build

# Ou avec Docker uniquement
docker build -t titanic-prediction .
docker run -v $(pwd)/output:/app/output titanic-prediction
```

Les rÃ©sultats seront disponibles dans le dossier `output/` montÃ© depuis votre machine hÃ´te.

## ğŸ“ Structure du projet

```
.
â”œâ”€â”€ src/                          # Code source principal
â”‚   â”œâ”€â”€ config.py                 # Configuration et paramÃ¨tres
â”‚   â”œâ”€â”€ data_preprocessing.py     # PrÃ©traitement des donnÃ©es
â”‚   â”œâ”€â”€ model_training.py         # EntraÃ®nement du modÃ¨le
â”‚   â”œâ”€â”€ model_evaluation.py       # Ã‰valuation et prÃ©dictions
â”‚   â””â”€â”€ main.py                   # Pipeline principal
â”œâ”€â”€ tests/                        # Tests unitaires (pytest)
â”‚   â”œâ”€â”€ test_preprocessing.py     # Tests du prÃ©traitement
â”‚   â”œâ”€â”€ test_training.py          # Tests de l'entraÃ®nement
â”‚   â””â”€â”€ test_evaluation.py        # Tests de l'Ã©valuation
â”œâ”€â”€ titanic/                      # DonnÃ©es d'entraÃ®nement et test
â”‚   â”œâ”€â”€ train.csv
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ gender_submission.csv
â”œâ”€â”€ output/                       # Fichiers de prÃ©dictions gÃ©nÃ©rÃ©s
â”œâ”€â”€ docs/                         # Documentation du projet
â”œâ”€â”€ .github/workflows/            # Pipelines CI/CD
â”‚   â”œâ”€â”€ python-ci.yml             # Tests, linting, formatage
â”‚   â””â”€â”€ docker-publish.yml        # Publication Docker
â”œâ”€â”€ Dockerfile                    # Configuration Docker
â”œâ”€â”€ docker-compose.yml            # Orchestration Docker
â”œâ”€â”€ requirements.txt              # DÃ©pendances Python
â””â”€â”€ setup.py                      # Configuration du package

```

## ğŸ§ª Tests

Le projet inclut une suite de tests unitaires complÃ¨te avec une couverture de 100% sur les modules fonctionnels.

```bash
# ExÃ©cuter tous les tests
pytest tests/

# Avec rapport de couverture
pytest tests/ --cov=src --cov-report=html

# ExÃ©cuter un test spÃ©cifique
pytest tests/test_preprocessing.py -v
```

**RÃ©sultats:**
- 40 tests unitaires
- 100% de rÃ©ussite
- Couverture complÃ¨te des modules fonctionnels

## ğŸ¤– ModÃ¨le

**Algorithme:** Random Forest Classifier

**ParamÃ¨tres:**
- `n_estimators`: 100 arbres
- `max_depth`: 5 niveaux maximum
- `random_state`: 1 (reproductibilitÃ©)

**Features utilisÃ©es:**
- `Pclass`: Classe du billet (1, 2, 3)
- `Sex`: Sexe du passager (encodÃ©: male=1, female=0)
- `SibSp`: Nombre de frÃ¨res/sÅ“urs/conjoints Ã  bord
- `Parch`: Nombre de parents/enfants Ã  bord

**Performance:**
- Score de validation croisÃ©e: ~80%
- ModÃ¨le optimisÃ© pour prÃ©venir le surapprentissage

## ğŸ”§ DÃ©veloppement

### QualitÃ© du code

Le projet utilise plusieurs outils pour maintenir la qualitÃ© du code:

```bash
# Linting (flake8)
flake8 src/*.py --max-line-length=88

# Formatage (black)
black src/*.py

# Tri des imports (isort)
isort src/*.py
```

### CI/CD Pipeline

Le projet est configurÃ© avec GitHub Actions pour:
1. **Tests automatiques** sur chaque push/PR
2. **VÃ©rification du linting** (flake8)
3. **VÃ©rification du formatage** (black)
4. **Rapport de couverture** des tests
5. **Publication Docker** (optionnel)

Pipeline dÃ©clenchÃ© sur les branches `main` et `develop`.

## ğŸ“Š Configuration

Les paramÃ¨tres du projet sont centralisÃ©s dans [src/config.py](../src/config.py):

```python
# ParamÃ¨tres du modÃ¨le
RANDOM_FOREST_PARAMS = {
    "n_estimators": 100,
    "max_depth": 5,
    "random_state": 1
}

# Features et cible
FEATURES = ["Pclass", "Sex", "SibSp", "Parch"]
TARGET = "Survived"
```

Pour modifier les paramÃ¨tres du modÃ¨le, Ã©ditez ce fichier avant l'exÃ©cution.

## ğŸ³ Docker

### Dockerfile

Le Dockerfile est optimisÃ© pour:
- Utiliser Python 3.9-slim (image lÃ©gÃ¨re)
- Mise en cache efficace des dÃ©pendances
- Variables d'environnement Python optimisÃ©es
- Installation du projet en mode Ã©ditable

### Docker Compose

Le fichier `docker-compose.yml` configure:
- Montage du volume `output/` pour rÃ©cupÃ©rer les rÃ©sultats
- RedÃ©marrage automatique (`unless-stopped`)
- Variables d'environnement Python

## ğŸ“š Documentation technique

### PrÃ©traitement des donnÃ©es (`data_preprocessing.py`)

1. **Chargement** des donnÃ©es depuis CSV
2. **Encodage** de la variable `Sex` (male=1, female=0)
3. **SÃ©lection** des features pertinentes
4. **Gestion** des valeurs manquantes (imputÃ©es avec la mÃ©diane)

### EntraÃ®nement (`model_training.py`)

1. **Initialisation** du Random Forest avec paramÃ¨tres configurÃ©s
2. **EntraÃ®nement** sur les donnÃ©es d'entraÃ®nement
3. **Retour** du modÃ¨le entraÃ®nÃ©

### Ã‰valuation (`model_evaluation.py`)

1. **Validation croisÃ©e** (5 folds) pour Ã©valuer la performance
2. **PrÃ©dictions** sur le jeu de test
3. **Export** des rÃ©sultats au format CSV

### Pipeline principal (`main.py`)

Orchestre l'exÃ©cution complÃ¨te:
1. PrÃ©traitement des donnÃ©es
2. EntraÃ®nement du modÃ¨le
3. Ã‰valuation et prÃ©dictions
4. Sauvegarde des rÃ©sultats

## ğŸ” Variables d'environnement

**Aucune variable d'environnement sensible n'est requise pour ce projet.**

Toutes les configurations sont statiques et peuvent rester dans le repository:
- Chemins de fichiers (locaux)
- ParamÃ¨tres du modÃ¨le (hyperparamÃ¨tres)
- Pas d'API keys ou credentials

**Si besoin futur de configuration flexible:**
- CrÃ©er un fichier `.env.example` avec les variables template
- Ajouter `.env` au `.gitignore` (dÃ©jÃ  fait)
- Utiliser `python-dotenv` pour charger les variables

## ğŸ‘¥ Contributeurs

**Ã‰tablissement:** IUT Paris CitÃ© - BUT VCOD 2025-2026

**DÃ©pÃ´t GitHub:** [Makamtrr/Dvt_Logiciel](https://github.com/Makamtrr/Dvt_Logiciel)

## ğŸ“„ Licence

Projet acadÃ©mique - IUT Paris CitÃ©

## ğŸ“ Support

Pour toute question ou problÃ¨me:
1. Ouvrir une [issue](https://github.com/Makamtrr/Dvt_Logiciel/issues) sur GitHub
2. Consulter la documentation dans `docs/`
3. VÃ©rifier les rapports d'Ã©tapes dans `rapports/`

---

**DerniÃ¨re mise Ã  jour:** FÃ©vrier 2026
